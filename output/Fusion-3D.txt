Fusion-3D: Integrated Acceleration for Instant 3D
Reconstruction and Real-Time Rendering
Sixu Li, Yang Zhao, Chaojian Li, Bowei Guo, Jingqun Zhang, Wenbo Zhu,
Zhifan Ye, Cheng Wan, Yingyan (Celine) Lin
School of Computer Science
Georgia Institute of Technology
Atlanta, GA, USA
{sli941, celine.lin}@gatech.edu
Abstract—Recent breakthroughs in Neural Radiance Field
(NeRF) based 3D reconstruction and rendering have spurred the
possibility of immersive experiences in augmented and virtual
reality (AR/VR). However, current NeRF acceleration techniques
are still inadequate for real-world AR/VR applications due to:
1) the lack of end-to-end pipeline acceleration support, which
causes impractical off-chip bandwidth demands for edge devices,
and 2) limited scalability in handling large-scale scenes. To tackle
these limitations, we have developed an end-to-end, scalable
3D acceleration framework called Fusion-3D, capable of instant
scene reconstruction and real-time rendering. Fusion-3D achieves
these goals through two key innovations: 1) an optimized end-to-
end processor for all three stages of the NeRF pipeline, featuring
dynamic scheduling and hardware-aware sampling in the first
stage, and a shared, reconfigurable pipeline with mixed-precision
arithmetic in the second and third stages; 2) a multi-chip archi-
tecture for handling large-scale scenes, integrating a three-level
hierarchical tiling scheme that minimizes inter-chip communica-
tion and balances workloads across chips. Extensive experiments
validate the effectiveness of Fusion-3D in facilitating real-time,
energy-efficient 3D reconstruction and rendering. Specifically,
we tape out a prototype chip in 28nm CMOS to evaluate the
effectiveness of the proposed end-to-end processor. Extensive
simulation based on the on-silicon measurements demonstrates
a 2.5× and 6× throughput improvement in training and in-
ference, respectively, compared to state-of-the-art accelerators.
Furthermore, to assess the multi-chip architecture, we integrate
four chips into a single PCB as a prototype. Further simulation
results show that the multi-chip system achieves a 7.3× and 6.5×
throughput improvement in training and inference, respectively,
over the Nvidia 2080Ti GPU. To the best of our knowledge,
Fusion-3D is the first to achieve both instant (≤2 seconds) 3D
reconstruction and real-time (≥30 FPS) rendering, while only
requiring the bandwidth of the most commonly used USB port
(0.625 GB/s, 5 Gbps) in edge devices for off-chip communication.
Index Terms—Neural Rendering, VLSI, Accelerator.
I. INTRODUCTION
3D reconstruction from sparsely sampled 2D images of
a scene is a foundational task in numerous augmented and
virtual reality (AR/VR) applications, as shown in Fig. 1 [48].
Neural Radiance Fields (NeRFs) have emerged as the state-
of-the-art (SOTA) method for 3D reconstruction, thanks to
their photorealistic rendering quality [28], [45]. Another ad-
vantage of NeRFs is their relatively small storage footprint,
approximately 10 MB of parameters [13], [28], which is
notably smaller than traditional methods such as point cloud
3D Reconstruction using
User A's Headset
Reconstructed Model
Render Any View Image With Photorealistic Quality
Loading the Model
100 MB
of
Pictures
A 10 MB
Model
Send a Compact-Sized Model to User B
Instant Reconstruction
on an Edge Device
Real-time Rendering
on an Edge Device
User A's Camera Takes Photos
X
Y
Z
Fig. 1. Illustrating NeRF-based 3D reconstruction and an application scenario.
reconstructions. This efficiency not only reduces communi-
cation bandwidth in latency-sensitive applications but is also
advantageous in scenarios with unstable network connections.
Moreover, real-world 3D reconstruction applications often
demand high performance, including instant training (recon-
struction) within 2 seconds [22], [29], [32] and real-time
inference (rendering) at a minimum of 30 FPS [47], [51],
which are essential for immersive experiences like virtual
telepresence [2]. Given the low storage needs of NeRFs [28]
and stringent performance requirements, there is a trend to-
wards conducting NeRF training and inference at the edge [6],
[22] to achieve lower latency and conserve network bandwidth.
Despite the growing demand for 3D reconstruction at the
edge, existing commercial edge devices, e.g., the NVIDIA
Xavier NX embedded system [33], still struggle to achieve
the aforementioned requirements of instant reconstruction and
real-time rendering. Currently, these capabilities are primarily
confined to high-end GPUs, like the NVIDIA RTX 3090 [5],
[31]. To bridge this gap, recent studies [10], [13], [16], [18],
[22], [30] have developed dedicated accelerators, aiming to
enable instant reconstruction and real-time rendering on edge
devices. These works propose tailored acceleration methods to
overcome the execution bottlenecks, advancing the potential of
edge 3D reconstruction solutions for real-world applications.
Despite existing NeRF accelerators’ promises, they still
fall short in meeting two critical requirements imposed by
real-world deployments: 1) the practical off-chip bandwidth
demand and 2) the efficient scaling-up strategy to support
78
2024 57th IEEE/ACM International Symposium on Microarchitecture (MICRO)
979-8-3503-5057-9/24/$31.00 ©2024 IEEE
DOI 10.1109/MICRO61859.2024.00016
2024 57th IEEE/ACM International Symposium on Microarchitecture (MICRO) | 979-8-3503-5057-9/24/$31.00 ©2024 IEEE | DOI: 10.1109/MICRO61859.2024.00016
Authorized licensed use limited to: University of Electronic Science and Tech of China. Downloaded on December 10,2024 at 09:01:00 UTC from IEEE Xplore.  Restrictions apply. 
Fusion-3D: Integrated Acceleration for Instant 3D
Reconstruction and Real-Time Rendering
Sixu Li, Yang Zhao, Chaojian Li, Bowei Guo, Jingqun Zhang, Wenbo Zhu,
Zhifan Ye, Cheng Wan, Yingyan (Celine) Lin
School of Computer Science
Georgia Institute of Technology
Atlanta, GA, USA
{sli941, celine.lin}@gatech.edu
Abstract—Recent breakthroughs in Neural Radiance Field
(NeRF) based 3D reconstruction and rendering have spurred the
possibility of immersive experiences in augmented and virtual
reality (AR/VR). However, current NeRF acceleration techniques
are still inadequate for real-world AR/VR applications due to:
1) the lack of end-to-end pipeline acceleration support, which
causes impractical off-chip bandwidth demands for edge devices,
and 2) limited scalability in handling large-scale scenes. To tackle
these limitations, we have developed an end-to-end, scalable
3D acceleration framework called Fusion-3D, capable of instant
scene reconstruction and real-time rendering. Fusion-3D achieves
these goals through two key innovations: 1) an optimized end-to-
end processor for all three stages of the NeRF pipeline, featuring
dynamic scheduling and hardware-aware sampling in the first
stage, and a shared, reconfigurable pipeline with mixed-precision
arithmetic in the second and third stages; 2) a multi-chip archi-
tecture for handling large-scale scenes, integrating a three-level
hierarchical tiling scheme that minimizes inter-chip communica-
tion and balances workloads across chips. Extensive experiments
validate the effectiveness of Fusion-3D in facilitating real-time,
energy-efficient 3D reconstruction and rendering. Specifically,
we tape out a prototype chip in 28nm CMOS to evaluate the
effectiveness of the proposed end-to-end processor. Extensive
simulation based on the on-silicon measurements demonstrates
a 2.5× and 6× throughput improvement in training and in-
ference, respectively, compared to state-of-the-art accelerators.
Furthermore, to assess the multi-chip architecture, we integrate
four chips into a single PCB as a prototype. Further simulation
results show that the multi-chip system achieves a 7.3× and 6.5×
throughput improvement in training and inference, respectively,
over the Nvidia 2080Ti GPU. To the best of our knowledge,
Fusion-3D is the first to achieve both instant (≤2 seconds) 3D
reconstruction and real-time (≥30 FPS) rendering, while only
requiring the bandwidth of the most commonly used USB port
(0.625 GB/s, 5 Gbps) in edge devices for off-chip communication.
Index Terms—Neural Rendering, VLSI, Accelerator.
I. INTRODUCTION
3D reconstruction from sparsely sampled 2D images of
a scene is a foundational task in numerous augmented and
virtual reality (AR/VR) applications, as shown in Fig. 1 [48].
Neural Radiance Fields (NeRFs) have emerged as the state-
of-the-art (SOTA) method for 3D reconstruction, thanks to
their photorealistic rendering quality [28], [45]. Another ad-
vantage of NeRFs is their relatively small storage footprint,
approximately 10 MB of parameters [13], [28], which is
notably smaller than traditional methods such as point cloud
3D Reconstruction using
User A's Headset
Reconstructed Model
Render Any View Image With Photorealistic Quality
Loading the Model
100 MB
of
Pictures
A 10 MB
Model
Send a Compact-Sized Model to User B
Instant Reconstruction
on an Edge Device
Real-time Rendering
on an Edge Device
User A's Camera Takes Photos
X
Y
Z
Fig. 1. Illustrating NeRF-based 3D reconstruction and an application scenario.
reconstructions. This efficiency not only reduces communi-
cation bandwidth in latency-sensitive applications but is also
advantageous in scenarios with unstable network connections.
Moreover, real-world 3D reconstruction applications often
demand high performance, including instant training (recon-
struction) within 2 seconds [22], [29], [32] and real-time
inference (rendering) at a minimum of 30 FPS [47], [51],
which are essential for immersive experiences like virtual
telepresence [2]. Given the low storage needs of NeRFs [28]
and stringent performance requirements, there is a trend to-
wards conducting NeRF training and inference at the edge [6],
[22] to achieve lower latency and conserve network bandwidth.
Despite the growing demand for 3D reconstruction at the
edge, existing commercial edge devices, e.g., the NVIDIA
Xavier NX embedded system [33], still struggle to achieve
the aforementioned requirements of instant reconstruction and
real-time rendering. Currently, these capabilities are primarily
confined to high-end GPUs, like the NVIDIA RTX 3090 [5],
[31]. To bridge this gap, recent studies [10], [13], [16], [18],
[22], [30] have developed dedicated accelerators, aiming to
enable instant reconstruction and real-time rendering on edge
devices. These works propose tailored acceleration methods to
overcome the execution bottlenecks, advancing the potential of
edge 3D reconstruction solutions for real-world applications.
Despite existing NeRF accelerators’ promises, they still
fall short in meeting two critical requirements imposed by
real-world deployments: 1) the practical off-chip bandwidth
demand and 2) the efficient scaling-up strategy to support
78
2024 57th IEEE/ACM International Symposium on Microarchitecture (MICRO)
979-8-3503-5057-9/24/$31.00 ©2024 IEEE
DOI 10.1109/MICRO61859.2024.00016
2024 57th IEEE/ACM International Symposium on Microarchitecture (MICRO) | 979-8-3503-5057-9/24/$31.00 ©2024 IEEE | DOI: 10.1109/MICRO61859.2024.00016
Authorized licensed use limited to: University of Electronic Science and Tech of China. Downloaded on December 10,2024 at 09:01:00 UTC from IEEE Xplore.  Restrictions apply. 
